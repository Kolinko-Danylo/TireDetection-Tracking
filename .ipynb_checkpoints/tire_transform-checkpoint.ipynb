{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_transformation(video_stream_path, output_path, rotation_angle, reshaping_coefs):\n",
    "    #transformation of badly centred pipeline\n",
    "    #detect pipeline boundaries, pull them out, transform of perspective\n",
    "    #then squeze ellipses into circles\n",
    "    \n",
    "    warp = None\n",
    "    index = 0\n",
    "    crop = None\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_stream_path)\n",
    "    if (cap.isOpened() == False): \n",
    "        print(\"Unable to read camera feed\")\n",
    "        \n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    M = cv2.getRotationMatrix2D((frame_width, frame_height), rotation_angle, 1)\n",
    "    M_inv = cv2.getRotationMatrix2D((frame_width, frame_height), -rotation_angle/2, 1)\n",
    "    size = (int(reshaping_coefs[0]*3*frame_width), int(reshaping_coefs[1]*3*frame_height))\n",
    "    new_size = None\n",
    "    \n",
    "    while(True):\n",
    "        ret, frame = cap.read() \n",
    "        warp = get_persp_transf(frame)\n",
    "        if warp is None: continue\n",
    "        else: \n",
    "            frame = cv2.warpPerspective(frame, warp, (3*frame_width, 3*frame_height))\n",
    "            frame = cv2.warpAffine(frame, M, (3*frame_width, 3*frame_height))\n",
    "\n",
    "            frame = cv2.resize(frame, size)\n",
    "\n",
    "            frame = cv2.warpAffine(frame, M_inv, size)\n",
    "\n",
    "            y, h, x, w = get_frame(frame)\n",
    "            crop = frame[y:y+h,x:x+w]\n",
    "            new_size = (y, h, x, w)\n",
    "\n",
    "            break\n",
    "\n",
    "    #TODO: estimate frame width and height and proper Transform from first frames of the scene.\n",
    "    out = cv2.VideoWriter(output_path,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (new_size[1], new_size[3]))\n",
    "\n",
    "    \n",
    "    while(True):\n",
    "        index += 1\n",
    "        if ((index % 50) == 0):\n",
    "            print(index)\n",
    "      \n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.warpPerspective(frame, warp, (3*frame_width, 3*frame_height))\n",
    "            \n",
    "            frame = cv2.warpAffine(frame, M, (3*frame_width, 3*frame_height))\n",
    "            frame = cv2.resize(frame, size)\n",
    "            frame = cv2.warpAffine(frame, M_inv, size)\n",
    "            crop = frame[new_size[2]:new_size[2]+new_size[3],new_size[0]:new_size[0]+new_size[1]]\n",
    "\n",
    "            out.write(crop)\n",
    "                    \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break \n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(img):\n",
    "    #remove black frame  around transformed video\n",
    "    \n",
    "    out = img.copy()\n",
    "    \n",
    "    gray = (cv2.cvtColor(out, cv2.COLOR_RGB2GRAY))\n",
    "    \n",
    "    \n",
    "    gratx = gray.sum(axis=1)\n",
    "    x = (gratx!=0).argmax()\n",
    "    gratx = gratx[x:]\n",
    "    gratx = gratx[:(gratx==0).argmax()]\n",
    "    \n",
    "    graty = gray.sum(axis=0)\n",
    "    y = (graty!=0).argmax()\n",
    "    graty = graty[y:]\n",
    "    graty = graty[:(graty==0).argmax()]\n",
    "    \n",
    "    return (y,graty.size, x, gratx.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def get_coords(coords, shape):\n",
    "    #Linear Algebra for boundary points, for each line get 2 points of intersection with frame bound\n",
    "    bound_vec_res = [0, 0, shape[0], shape[1]]\n",
    "    bound_vec = [[1, 0],[0, 1], [1, 0], [0, 1]]\n",
    "    \n",
    "    \n",
    "    coord_vec = [1/(coords[1][1] - coords[0][1]), - 1/(coords[1][0] - coords[0][0])]\n",
    "    coord_res = coords[0][1]/(coords[1][1] - coords[0][1]) - coords[0][0]/(coords[1][0] - coords[0][0])\n",
    "    res_t = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        inv = np.linalg.inv(np.array([bound_vec[i], coord_vec]))\n",
    "        b = np.array([bound_vec_res[i], coord_res])\n",
    "        res = np.matmul(inv, b)\n",
    "        if (0 <= res[0] <= shape[0]) and (0 <= res[1] <= shape[1]):\n",
    "            res_t.append(np.int32(res[::-1]))\n",
    "    return res_t\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_pipeline_borders(image):\n",
    "    #houghlines + seed out everything but pipeline bounds\n",
    "    img = image.copy()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,120)\n",
    "    sort = []\n",
    "    lrightest = [(0,0), (0,0), 0]\n",
    "    lleftest = [(0,0), (0,0), 0]\n",
    "    if lines is not None:\n",
    "        for i in range(len(lines)):\n",
    "            for rho,theta in lines[i]:\n",
    "                a = np.cos(theta) \n",
    "                b = np.sin(theta)\n",
    "                x0 = a*rho\n",
    "                y0 = b*rho\n",
    "                x1 = int(x0 + 1000*(-b))\n",
    "                y1 = int(y0 + 1000*(a))\n",
    "                x2 = int(x0 - 1000*(-b))\n",
    "                y2 = int(y0 - 1000*(a))\n",
    "\n",
    "                sort.append([(x1, y1), (x2, y2), theta])\n",
    "\n",
    "        rightest = max(sort, key=lambda x: x[0][0] + x[1][0] if (x[2] - np.pi < 0) else lrightest) \n",
    "        if rightest != lrightest:\n",
    "            xy1, xy2 = get_coords(rightest, img.shape)\n",
    "            rightest = [tuple(xy1), tuple(xy2)]\n",
    "            cv2.line(img,*rightest,(0,0,255),2)\n",
    "        else: \n",
    "            return None, None\n",
    "        leftest = min(sort, key=lambda x: x[0][0] + x[1][0] if (x[2] - np.pi > 0) else lleftest)\n",
    "        if leftest != lleftest:\n",
    "            xy1, xy2 = get_coords(leftest, img.shape)\n",
    "            leftest = [tuple(xy1), tuple(xy2)]\n",
    "            cv2.line(img,*leftest,(0,0,255),2)\n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "   \n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    return rightest, leftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "def order_points(pts):\n",
    "    # sort the points based on their x-coordinates\n",
    "    pts = np.array(pts)\n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    " \n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    " \n",
    "\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (tl, bl) = leftMost\n",
    " \n",
    "    D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "    (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    " \n",
    "\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_persp_transf(img):\n",
    "\n",
    "    rightest, leftest = detect_pipeline_borders(img)\n",
    "    if rightest is None:\n",
    "        return None\n",
    "    pointset = [*leftest, *rightest]\n",
    "    for i in range(len(pointset)):\n",
    "        pointset[i] = list(pointset[i])\n",
    "    pointset = order_points(pointset)\n",
    "\n",
    "    \n",
    "    if pointset[-1][0] == 0 and pointset[0][0] != 0:\n",
    "        pointset = np.insert(pointset[:3], 0, pointset[3], axis=0)\n",
    "    pointset[[2,3]] = pointset[[3,2]]\n",
    "\n",
    "     \n",
    "    rows,cols,ch = img.shape\n",
    "    pts1 = np.float32([pointset])\n",
    "    pts2 = np.float32([[0,0],[cols,0],[0,rows],[cols,rows]])\n",
    "    \n",
    "\n",
    "    N = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_transformation(\"ObjectDetectionSample2.mp4\", \"ProcessedODSample2.mp4\", 45, (1, 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
