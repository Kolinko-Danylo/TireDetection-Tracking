{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run tire_transform.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "\n",
    "\n",
    "def detect_tires(output, gray_scale=False):\n",
    "    # Hough Circles detection requires min radius and \n",
    "    # dp (inverse ratio of the accumulator resolution to the image resolution) are \n",
    "    # video dependent (pipeline-size dependent ---> video height dependent). Therefore we use default params.\n",
    "    default_param = 1.2\n",
    "    default_height = 260\n",
    "    minr = 40\n",
    "    \n",
    "    scale = output.shape[0]/default_height\n",
    "    \n",
    "    \n",
    "    gray = (cv2.cvtColor(output, cv2.COLOR_RGB2GRAY) if not gray_scale else output)\n",
    "\n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, default_param/scale, 100, minRadius=int(minr*scale), maxRadius=400, param1 = 100, param2 = 80)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = circles[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    circles = circles[~np.all(circles == 0, axis=1)]\n",
    "\n",
    "    circles = np.round(circles[:]).astype(\"int\")\n",
    "    if (circles.size==0): return None\n",
    "    \n",
    "    filtred_circles = [True for i in range(circles.shape[0])]\n",
    "    \n",
    "    #filter out circels with high IoU\n",
    "    iou_threshold = 0.2\n",
    "    for i in range(circles.shape[0]):\n",
    "        for j in range(circles.shape[0]):\n",
    "            area = inter_area(circles[i], circles[j])\n",
    "            if i !=j and area!=0:\n",
    "                \n",
    "                area_1 = math.pi* circles[i][2]**2\n",
    "                area_2 = math.pi* circles[j][2]**2\n",
    "                \n",
    "                if area/min(area_1, area_2) > iou_threshold:\n",
    "                    \n",
    "                    if circles[i][2] > circles[j][2]:                      \n",
    "                        filtred_circles[j] = False \n",
    "                    else:\n",
    "                        filtred_circles[i] = False\n",
    "                        \n",
    "\n",
    "    return circles[filtred_circles]\n",
    "\n",
    "\n",
    "def draw_circles(img, circles_array):\n",
    "    if circles_array is None:\n",
    "        return img\n",
    "\n",
    "    output = img.copy()\n",
    "    for (x, y, r) in circles_array:\n",
    "        cv2.circle(output, (x, y), r, (255, 0, 0), 4)\n",
    "        cv2.rectangle(output, (x - r, y - r), (x + r, y + r), (0, 255, 255), 0)\n",
    "        cv2.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (255, 128, 0), -1)\n",
    "    return output\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import asin, sqrt, pi\n",
    "def inter_area(A, B):\n",
    "    # A, B - (x,y,r) of circle\n",
    "    d = sqrt((B[0] - A[0])**2 + (B[0] - A[0])**2)\n",
    "\n",
    "    if (d < A[2] + B[2]):\n",
    "        \n",
    "        r1_2 = A[2]**2\n",
    "        r2_2 = B[2]**2\n",
    "        \n",
    "        if (d < abs(B[2] - A[2])):\n",
    "            return pi * min(r1_2, r2_2)\n",
    "        \n",
    "        x = (r1_2 - r2_2 + d**2) / (2 * d)\n",
    "        z = x**2\n",
    "        y = sqrt(r1_2 - z)\n",
    "\n",
    "        return r1_2 * asin(y / A[2]) + r2_2 * asin(y / B[2]) - y * (x + sqrt(z + r2_2 - r2_2))\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def video_creation_hough(input_path, output_path, warp_flag=False):\n",
    "\n",
    "    trans_path = 'transformed_stream.mp4'\n",
    "    index = 0\n",
    "    \n",
    "    if warp_flag:\n",
    "        video_stream_path(input_path, trans_path, 45, (1, 0.5))\n",
    "        input_path = trans_path\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if (cap.isOpened() == False): \n",
    "        print(\"Unable to read camera feed\")\n",
    "            \n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    #TODO: estimate frame width and height and proper Transform from first frames of the scene.\n",
    "    out = cv2.VideoWriter(output_path,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width, frame_height))\n",
    "    \n",
    "    while(True):\n",
    "        \n",
    "        index += 1\n",
    "        if ((index % 50) == 0):\n",
    "            print(index)\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if ret == True: \n",
    "            detected = draw_circles(frame, detect_tires(frame))\n",
    "            cv2.imshow('k', detected)\n",
    "            out.write(detected)\n",
    "                    \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break \n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "#video_creation_hough(\"video_folder/ProcessedODSample2.mp4\", \"video_folder/HoughDetectedSample.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
